{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Statements\n",
    "### The libraries used are `pandas`, `pathlib`, `imblearn`, and `sklearn`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the data and create a dataframe\n",
    "1. Use `pandas` and `pathlib` to read the `BankChurnersPrimary.csv` CSV from the `Resources` folder.\n",
    "2. Sample the dataset to review the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starter_df = pd.read_csv(Path(\"c://users/ajcth/documents/github/bank_churn_project/Resources/BankChurnersPrimary.csv\"))\n",
    "starter_df.sample(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1519 Unknowns in Education\n",
    "\n",
    "749 Unknowns in Marital_Status\n",
    "\n",
    "1112 Unknowns in Income_Category\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starter_df = starter_df.drop(columns=['Education_Level', 'Marital_Status', 'Income_Category'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop any Unknown or NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#starter_df = starter_df[starter_df != 'Unknown'].dropna()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove any columns that won't be used.\n",
    "Naive Bayes columns can't be used (it's calculated from features and target).\n",
    "\n",
    "CLIENTNUM is irrelevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starter_df.drop(columns=[\n",
    "'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2', \n",
    "'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1',\n",
    "'CLIENTNUM'\n",
    "], \n",
    "inplace= True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Education column for use as a feature\n",
    "The Education values are ranked from uneducated to doctorate, and is a gradient rather than ambiguous classifications. \n",
    "\n",
    "The ranks will be converted to numericals and specified as datatype `int`.\n",
    "1. Uneducated = 0\n",
    "2. Highschool = 1\n",
    "3. College = 2\n",
    "4. Graduate = 3\n",
    "5. Post-Grad = 4\n",
    "6. Doctorate = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "starter_df = starter_df.replace({'Education_Level' : {\n",
    "'Uneducated': 0, \n",
    "'High School': 1, \n",
    "'College' : 2, \n",
    "'Graduate' :  3, \n",
    "'Post-Graduate' : 4, \n",
    "'Doctorate' : 5\n",
    "}})\n",
    "starter_df.Education_Level = starter_df.Education_Level.astype(int)\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Card Type column for use as a feature\n",
    "The Card Type values are ranked from blue to platinum, and is a gradient rather than ambiguous classifications. The ranks will be converted to numericals and specified as datatype `int`.\n",
    "1. Blue = 0\n",
    "2. Silver = 1\n",
    "3. Gold = 2\n",
    "4. Platinum = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starter_df = starter_df.replace({'Card_Category' : {\n",
    "'Blue': 0, \n",
    "'Silver': 1, \n",
    "'Gold' : 2, \n",
    "'Platinum' : 3\n",
    "}})\n",
    "starter_df.Card_Category = starter_df.Card_Category.astype(int)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Gender column for use as a feature\n",
    "Gender is a binary classification, so we don't need to OneHotEncode.\n",
    "The values will be converted to numericals and specified as datatype `int`.\n",
    "1. Male = 0\n",
    "2. Female = 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starter_df = starter_df.replace({'Gender' : {\n",
    "'M': 0, \n",
    "'F': 1\n",
    "}})\n",
    "starter_df.Gender = starter_df.Gender.astype(int)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Attrition_Flag column for use as the target\n",
    "Attrition_Flag is a binary classification, so we don't need to OneHotEncode.\n",
    "The values will be converted to numericals and specified as datatype `int`.\n",
    "1. Attrited Customer = 0\n",
    "2. Existing Customer = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starter_df = starter_df.replace({'Attrition_Flag' : {\n",
    "'Attrited Customer': 0, \n",
    "'Existing Customer': 1\n",
    "}})\n",
    "starter_df.Attrition_Flag = starter_df.Attrition_Flag.astype(int)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform feature creation on the Dependents and Marital_Status features to create the Marital_Dependent_Ratio feature\n",
    "The values will be converted to numericals and specified as datatype `int`.\n",
    "Divorced and Single will be combined, as they are both single income sources.\n",
    "1. Divorced = 1\n",
    "2. Single = 1 \n",
    "3. Married = 2\n",
    "\n",
    "The formula for Marital_Dependent_Ratio is as follows:\n",
    "\n",
    "( Marital_Status / (Dependents + 1) / 2 )\n",
    "\n",
    "The original Marital_Status and Dependents columns will be dropped in place of the Marital_Dependent_Ratio column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "starter_df = starter_df.replace({'Marital_Status' : {\n",
    "'Divorced': 1, \n",
    "'Single': 1, \n",
    "'Married' : 2\n",
    "}})\n",
    "starter_df.Marital_Status = starter_df.Marital_Status.astype(int)\n",
    "starter_df['Marital_Dependent_Ratio'] = ((starter_df['Marital_Status'] / (starter_df['Dependent_count'] + 1)) / 2).round(2)\n",
    "starter_df.drop(columns=['Marital_Status', 'Dependent_count'], inplace=True)\n",
    "'''\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform feature creation on the Avg_Open_To_Buy and Credit_Limit features to create the Avg_Trans_Value feature. Its a simple ratio.\n",
    "The original Avg_Open_To_Buy and Credit_Limit columns will be dropped in place of the Credit_Usage column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starter_df['Credit_Usage'] = (starter_df['Avg_Open_To_Buy'] / starter_df['Credit_Limit']).round(2)\n",
    "starter_df.drop(columns=['Avg_Open_To_Buy', 'Credit_Limit'], inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform feature creation on the Total_Trans_Amt and Total_Trans_Ct features to create the Avg_Trans_Value feature. Its a simple ratio.\n",
    "The original Total_Trans_Amt and Total_Trans_Ct columns will be dropped in place of the Avg_Trans_Value column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starter_df['Avg_Trans_Value'] = (starter_df['Total_Trans_Amt'] / starter_df['Total_Trans_Ct']).round(2)\n",
    "starter_df.drop(columns=['Total_Trans_Amt', 'Total_Trans_Ct'], inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform feature creation on the Tenure(month) and Age features to create the Tenure_By_Age feature. Its a simple ratio.\n",
    "\n",
    "The original Tenure(month) and Age columns will be dropped in place of the Tenure_By_Age column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do feature creation to make a ratio between age and tenure\n",
    "starter_df['Tenure_By_Age'] = (starter_df['Months_on_book'] / starter_df['Customer_Age']).round(2)\n",
    "starter_df.drop(columns=['Months_on_book', 'Customer_Age'], inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Income column for use as the target\n",
    " The Income values are ranked in blocks, and is a gradient rather than ambiguous classifications. The ranks will be converted to numericals and specified as datatype `int`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "starter_df = starter_df.replace({'Income_Category' : {\n",
    "'Less than $40K': 0, \n",
    "'$40K - $60K': 1, \n",
    "'$80K - $120K' : 2, \n",
    "'$60K - $80K' : 3, \n",
    "'$120K +' : 4\n",
    "}})\n",
    "starter_df.Income_Category = starter_df.Income_Category.astype(int)\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review the new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starter_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starter_df.sample(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define our features(X) and our target(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = starter_df['Attrition_Flag']\n",
    "X = starter_df.drop(columns=['Attrition_Flag'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split features and target in to training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using StandardScaler, scale all numerical/float values that don't represent ambiguous categories\n",
    "### StandardScaler will be used within ColumnTransformer. This allows for the scaling of specified columns within our X_train and X_test set.\n",
    "It's critical that the StandardScaler is only fit to our X_train. Both X_train and X_test will be transformed, but the StandardScaler will only be fit to X_train.This prevents the model from 'cheating'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "col_tran= ColumnTransformer([\n",
    "('Total_Revolving_Bal_Scaled', scaler, ['Total_Revolving_Bal']),\n",
    "#('Education_Scaled', scaler, ['Education_Level']),\n",
    "#('Income_Scaled', scaler, ['Income_Category']),\n",
    "('Card_Type_Scaled', scaler, ['Card_Category']),\n",
    "('Months_Inactive_12_mon_scaled', scaler, ['Months_Inactive_12_mon']),\n",
    "('Credit_Usage_Scaled', scaler, ['Credit_Usage']),\n",
    "('Avg_Trans_Value_Scaled', scaler, ['Avg_Trans_Value']),\n",
    "('Tenure_By_Age_Scaled', scaler, ['Tenure_By_Age']),\n",
    "('Avg_Util_Ratio_Scaled', scaler, ['Avg_Utilization_Ratio']),\n",
    "('Total_Relationship_Count_Scaled', scaler, ['Total_Relationship_Count']),\n",
    "('Contacts_Count_12_mon_scaled', scaler, ['Contacts_Count_12_mon']),\n",
    "('Total_Amt_Chng_Q4_Q1_scaled', scaler, ['Total_Amt_Chng_Q4_Q1']),\n",
    "('Total_Ct_Chng_Q4_Q1_scaled', scaler, ['Total_Ct_Chng_Q4_Q1']),\n",
    "#('Marital_Dependent_Ratio_Scaled', scaler, ['Marital_Dependent_Ratio']),\n",
    "('Dependent_count', scaler, ['Dependent_count'])\n",
    "])\n",
    "\n",
    "\n",
    "X_train = col_tran.fit_transform(X_train)\n",
    "X_test = col_tran.transform(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use SMOTE to add synthetic data and balance our target/feature value count\n",
    "This will only be done on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = SMOTE()\n",
    "X_train, y_train = oversample.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "#'n_estimators' : [100, 300],\n",
    "#'random_state' : [1, 2],\n",
    "'subsample' : [1, 0.9],\n",
    "'min_samples_split' : [2, 3],\n",
    "#'max_depth' : [3, 2],\n",
    "'min_impurity_decrease' : [0, 1],\n",
    "#'min_samples_leaf' : [1, 2],\n",
    "'min_weight_fraction_leaf' : [0, 0.1],\n",
    "'max_leaf_nodes' : [None, 2],\n",
    "#'learning_rate' : [0.1, 0.0],\n",
    "'criterion' : ('friedman_mse', 'squared_error'),\n",
    "'init' : ('zero', None),\n",
    "'loss' : ('log_loss', 'deviance', 'exponential')\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "gbc = GradientBoostingClassifier(n_estimators=500, random_state=2)\n",
    "clf = GridSearchCV(gbc, parameters)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(clf.cv_results_.keys())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an instance of the GradientBoostingClassifier model\n",
    "Hyperparameter tuning was mostly unhelpful; only two hyperparameters have been changed from default values.\n",
    "1. n_estimators = 500\n",
    "2. random_state= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc_model = GradientBoostingClassifier(\n",
    "n_estimators=500,                 #default = 100    range = 1-inf\n",
    "random_state= 2,                  #default = None   range = 1-inf\n",
    "subsample= 1,                     #default = 1      range = 0.-1\n",
    "min_samples_split = 2,            #default = 2      range = 2-inf\n",
    "max_depth=3,                      #default = 3      range = 1-inf\n",
    "min_impurity_decrease=0,          #default = 0      range = 0 - inf\n",
    "min_samples_leaf = 1,             #default = 1      range = 1 - inf\n",
    "min_weight_fraction_leaf = 0,     #default = 0      range =0 - 0.5\n",
    "max_leaf_nodes = None,            #default = None   range = 2-inf\n",
    "learning_rate = 0.1               #default=0.1      range 0.0-inf\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc_model.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc_test_predictions = gbc_model.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, gbc_test_predictions)\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc_test_matrix = confusion_matrix(y_test, gbc_test_predictions)\n",
    "print(gbc_test_matrix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc_testing_report = classification_report(y_test, gbc_test_predictions)\n",
    "print(gbc_testing_report)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate an imbalanced classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imb__gbc_testing_report = classification_report_imbalanced(y_test, gbc_test_predictions)\n",
    "print(imb__gbc_testing_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "28515e2b63b40114f6e8c1f789cf21b6d4b349a50273d5a1dcb37706cefab85d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
